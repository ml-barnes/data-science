{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.4'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Almost state-of-the-art computer vision\n",
    "\n",
    "Keras comes prepackaged with some of the state-of-the-art machine vision models that have been previously pretrained on large clusters of GPUs using millions of images as training data. \n",
    "\n",
    "Using this pre-train models, you have programmatic access to state-of-the-art machine vision that you can incorporate into your software projects. Here is the list of image classification models (all pre-trained on the ImageNet dataset) that are available as part of `keras.applications`:\n",
    "\n",
    "* Xception\n",
    "* InceptionV3\n",
    "* ResNet50\n",
    "* VGG16\n",
    "* VGG19\n",
    "* MobileNet\n",
    "\n",
    "Let's instantiate ResNet50 and check out its performance on the following images\n",
    "\n",
    "<img src=\"./images/car.jpg\" alt=\"Drawing\" style=\"height: 200px; float: left;\"/>\n",
    "<img src=\"./images/elephant.jpg\" alt=\"Drawing\" float=\"left\" style=\"height: 200px;  float: left;\"/>\n",
    "<img src=\"./images/chair.jpg\" alt=\"Drawing\" style=\"height: 200px; float: left;\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [[('n04285008', 'sports_car', 0.37167186), ('n02930766', 'cab', 0.14883095), ('n02814533', 'beach_wagon', 0.09638426), ('n03930630', 'pickup', 0.06842637), ('n04037443', 'racer', 0.055562854)]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.applications import ResNet50\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.imagenet_utils import preprocess_input, decode_predictions\n",
    "\n",
    "model = ResNet50(weights='imagenet')\n",
    "\n",
    "img_path = './images/car.jpg'\n",
    "# img_path = './images/elephant.jpg'\n",
    "# img_path = './images/chair.jpg'\n",
    "\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "preds = model.predict(x)\n",
    "print('Predicted:', decode_predictions(preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the name of the input file and check the performance of the ResNet50 model on the other images, or some images of your choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning - Using a pre-trained convnet\n",
    "\n",
    "A common and highly effective approach to deep learning on small image datasets is to leverage a pre-trained network. A pre-trained network is simply a saved network previously trained on a large dataset, typically on a large-scale image classification task. If this original dataset is large enough and general enough, then the spatial feature hierarchy learned by the pre-trained network can effectively act as a generic model of our visual world, and hence its features can prove useful for many different computer vision problems, even though these new problems might involve completely different classes from those of the original task. For instance, one might train a network on ImageNet (where classes are mostly animals and everyday objects) and then re-purpose this trained network for something as remote as identifying furniture items in images. Such portability of learned features across different problems is a key advantage of deep learning compared to many older shallow learning approaches, and it makes deep learning very effective for small-data problems.\n",
    "\n",
    "In our case, we will consider a large convnet trained on the ImageNet dataset (1.4 million labeled images and 1000 different classes). \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction\n",
    "\n",
    "Feature extraction consists of using the representations learned by a previous network to extract interesting features from new samples. These features are then run through a new classifier, which is trained from scratch.\n",
    "\n",
    "As we saw previously, convnets used for image classification comprise two parts: they start with a series of pooling and convolution layers, and they end with a densely-connected classifier. The first part is called the \"convolutional base\" of the model. In the case of convnets, \"feature extraction\" will simply consist of taking the convolutional base of a previously-trained network, running the new data through it, and training a new classifier on top of the output.\n",
    "\n",
    "![swapping FC classifiers](./images/swapping_fc_classifier.png)\n",
    "\n",
    "Why only reuse the convolutional base? Could we reuse the densely-connected classifier as well? In general, it should be avoided. The reason is simply that the representations learned by the convolutional base are likely to be more generic and therefore more reusable: the feature maps of a convnet are presence maps of generic concepts over a picture, which is likely to be useful regardless of the computer vision problem at hand. On the other end, the representations learned by the classifier will necessarily be very specific to the set of  classes that the model was trained on -- they will only contain information about the presence probability of this or that class in the entire picture. Additionally, representations found in densely-connected layers no longer contain any information about _where_ objects are located in the input image: these layers get rid of the notion of space, whereas the object location is still described by convolutional feature maps. For problems where object location matters, densely-connected features would be largely useless.\n",
    "\n",
    "Note that the level of generality (and therefore reusability) of the representations extracted by specific convolution layers depends on the depth of the layer in the model. Layers that come earlier in the model extract local, highly generic feature maps (such as visual edges, colors, and textures), while layers higher-up extract more abstract concepts (such as \"cat ear\" or \"dog eye\"). So if your new dataset differs a lot from the dataset that the original model was trained on, you may be better off using only the first few layers of the model to do feature extraction, rather than using the entire convolutional base."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's put this in practice by using the convolutional base of the InceptionV3 network, trained on ImageNet, to extract interesting features from the data set of cats and dog images we used in the previous practical, and then training a cat vs. dog classifier on top of these features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's instantiate the InceptionV3 model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import InceptionV3\n",
    "\n",
    "conv_base = InceptionV3(weights='imagenet',\n",
    "                  include_top=False,\n",
    "                  input_shape=(150, 150, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We passed three arguments to the constructor:\n",
    "\n",
    "* `weights`, to specify which weight checkpoint to initialize the model from\n",
    "* `include_top`, which refers to including or not the densely-connected classifier on top of the network. By default, this \n",
    "densely-connected classifier would correspond to the 1000 classes from ImageNet. Since we intend to use our own densely-connected \n",
    "classifier (with only two classes, cat and dog), we don't need to include it.\n",
    "* `input_shape`, the shape of the image tensors that we will feed to the network. This argument is purely optional: if we don't pass it, \n",
    "then the network will be able to process inputs of any size.\n",
    "\n",
    "Here's the detail of the architecture of the InceptionV3 convolutional base: it's very similar to the simple convnets that you are already familiar with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            (None, 150, 150, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 74, 74, 32)   864         input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 74, 74, 32)   96          conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_340 (Activation)     (None, 74, 74, 32)   0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 72, 72, 32)   9216        activation_340[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 72, 72, 32)   96          conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_341 (Activation)     (None, 72, 72, 32)   0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 72, 72, 64)   18432       activation_341[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 72, 72, 64)   192         conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_342 (Activation)     (None, 72, 72, 64)   0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 35, 35, 64)   0           activation_342[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 35, 35, 80)   5120        max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 35, 35, 80)   240         conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_343 (Activation)     (None, 35, 35, 80)   0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 33, 33, 192)  138240      activation_343[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 33, 33, 192)  576         conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_344 (Activation)     (None, 33, 33, 192)  0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 16, 16, 192)  0           activation_344[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 16, 16, 64)   12288       max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 16, 16, 64)   192         conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_348 (Activation)     (None, 16, 16, 64)   0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 16, 16, 48)   9216        max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 16, 16, 96)   55296       activation_348[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 16, 16, 48)   144         conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 16, 16, 96)   288         conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_346 (Activation)     (None, 16, 16, 48)   0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_349 (Activation)     (None, 16, 16, 96)   0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_10 (AveragePo (None, 16, 16, 192)  0           max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 16, 16, 64)   12288       max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 16, 16, 64)   76800       activation_346[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 16, 16, 96)   82944       activation_349[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 16, 16, 32)   6144        average_pooling2d_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 16, 16, 64)   192         conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 16, 16, 64)   192         conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 16, 16, 96)   288         conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 16, 16, 32)   96          conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_345 (Activation)     (None, 16, 16, 64)   0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_347 (Activation)     (None, 16, 16, 64)   0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_350 (Activation)     (None, 16, 16, 96)   0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_351 (Activation)     (None, 16, 16, 32)   0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_345[0][0]             \n",
      "                                                                 activation_347[0][0]             \n",
      "                                                                 activation_350[0][0]             \n",
      "                                                                 activation_351[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, 16, 16, 64)   192         conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_355 (Activation)     (None, 16, 16, 64)   0           batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 16, 16, 96)   55296       activation_355[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, 16, 16, 48)   144         conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, 16, 16, 96)   288         conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_353 (Activation)     (None, 16, 16, 48)   0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_356 (Activation)     (None, 16, 16, 96)   0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_11 (AveragePo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 16, 16, 64)   76800       activation_353[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 16, 16, 96)   82944       activation_356[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 16, 16, 64)   16384       average_pooling2d_11[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, 16, 16, 64)   192         conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, 16, 16, 64)   192         conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, 16, 16, 96)   288         conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, 16, 16, 64)   192         conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_352 (Activation)     (None, 16, 16, 64)   0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_354 (Activation)     (None, 16, 16, 64)   0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_357 (Activation)     (None, 16, 16, 96)   0           batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_358 (Activation)     (None, 16, 16, 64)   0           batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_352[0][0]             \n",
      "                                                                 activation_354[0][0]             \n",
      "                                                                 activation_357[0][0]             \n",
      "                                                                 activation_358[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, 16, 16, 64)   192         conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_362 (Activation)     (None, 16, 16, 64)   0           batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 16, 16, 96)   55296       activation_362[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, 16, 16, 48)   144         conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (None, 16, 16, 96)   288         conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_360 (Activation)     (None, 16, 16, 48)   0           batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_363 (Activation)     (None, 16, 16, 96)   0           batch_normalization_118[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_12 (AveragePo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 16, 16, 64)   76800       activation_360[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 16, 16, 96)   82944       activation_363[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 16, 16, 64)   18432       average_pooling2d_12[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 16, 16, 64)   192         conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, 16, 16, 64)   192         conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, 16, 16, 96)   288         conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchN (None, 16, 16, 64)   192         conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_359 (Activation)     (None, 16, 16, 64)   0           batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_361 (Activation)     (None, 16, 16, 64)   0           batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_364 (Activation)     (None, 16, 16, 96)   0           batch_normalization_119[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_365 (Activation)     (None, 16, 16, 64)   0           batch_normalization_120[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_359[0][0]             \n",
      "                                                                 activation_361[0][0]             \n",
      "                                                                 activation_364[0][0]             \n",
      "                                                                 activation_365[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchN (None, 16, 16, 64)   192         conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_367 (Activation)     (None, 16, 16, 64)   0           batch_normalization_122[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, 16, 16, 96)   55296       activation_367[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchN (None, 16, 16, 96)   288         conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_368 (Activation)     (None, 16, 16, 96)   0           batch_normalization_123[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 7, 7, 96)     82944       activation_368[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchN (None, 7, 7, 384)    1152        conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchN (None, 7, 7, 96)     288         conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_366 (Activation)     (None, 7, 7, 384)    0           batch_normalization_121[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_369 (Activation)     (None, 7, 7, 96)     0           batch_normalization_124[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling2D) (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_366[0][0]             \n",
      "                                                                 activation_369[0][0]             \n",
      "                                                                 max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchN (None, 7, 7, 128)    384         conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_374 (Activation)     (None, 7, 7, 128)    0           batch_normalization_129[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, 7, 7, 128)    114688      activation_374[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchN (None, 7, 7, 128)    384         conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_375 (Activation)     (None, 7, 7, 128)    0           batch_normalization_130[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, 7, 7, 128)    114688      activation_375[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchN (None, 7, 7, 128)    384         conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchN (None, 7, 7, 128)    384         conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_371 (Activation)     (None, 7, 7, 128)    0           batch_normalization_126[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_376 (Activation)     (None, 7, 7, 128)    0           batch_normalization_131[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, 7, 7, 128)    114688      activation_371[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, 7, 7, 128)    114688      activation_376[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchN (None, 7, 7, 128)    384         conv2d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_132 (BatchN (None, 7, 7, 128)    384         conv2d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_372 (Activation)     (None, 7, 7, 128)    0           batch_normalization_127[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_377 (Activation)     (None, 7, 7, 128)    0           batch_normalization_132[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_13 (AveragePo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, 7, 7, 192)    172032      activation_372[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, 7, 7, 192)    172032      activation_377[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_13[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchN (None, 7, 7, 192)    576         conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchN (None, 7, 7, 192)    576         conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_133 (BatchN (None, 7, 7, 192)    576         conv2d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_134 (BatchN (None, 7, 7, 192)    576         conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_370 (Activation)     (None, 7, 7, 192)    0           batch_normalization_125[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_373 (Activation)     (None, 7, 7, 192)    0           batch_normalization_128[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_378 (Activation)     (None, 7, 7, 192)    0           batch_normalization_133[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_379 (Activation)     (None, 7, 7, 192)    0           batch_normalization_134[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_370[0][0]             \n",
      "                                                                 activation_373[0][0]             \n",
      "                                                                 activation_378[0][0]             \n",
      "                                                                 activation_379[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_139 (BatchN (None, 7, 7, 160)    480         conv2d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_384 (Activation)     (None, 7, 7, 160)    0           batch_normalization_139[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (None, 7, 7, 160)    179200      activation_384[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_140 (BatchN (None, 7, 7, 160)    480         conv2d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_385 (Activation)     (None, 7, 7, 160)    0           batch_normalization_140[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)             (None, 7, 7, 160)    179200      activation_385[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_136 (BatchN (None, 7, 7, 160)    480         conv2d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_141 (BatchN (None, 7, 7, 160)    480         conv2d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_381 (Activation)     (None, 7, 7, 160)    0           batch_normalization_136[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_386 (Activation)     (None, 7, 7, 160)    0           batch_normalization_141[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)             (None, 7, 7, 160)    179200      activation_381[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)             (None, 7, 7, 160)    179200      activation_386[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_137 (BatchN (None, 7, 7, 160)    480         conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_142 (BatchN (None, 7, 7, 160)    480         conv2d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_382 (Activation)     (None, 7, 7, 160)    0           batch_normalization_137[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_387 (Activation)     (None, 7, 7, 160)    0           batch_normalization_142[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_14 (AveragePo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)             (None, 7, 7, 192)    215040      activation_382[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)             (None, 7, 7, 192)    215040      activation_387[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_14[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_135 (BatchN (None, 7, 7, 192)    576         conv2d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_138 (BatchN (None, 7, 7, 192)    576         conv2d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_143 (BatchN (None, 7, 7, 192)    576         conv2d_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_144 (BatchN (None, 7, 7, 192)    576         conv2d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_380 (Activation)     (None, 7, 7, 192)    0           batch_normalization_135[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_383 (Activation)     (None, 7, 7, 192)    0           batch_normalization_138[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_388 (Activation)     (None, 7, 7, 192)    0           batch_normalization_143[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_389 (Activation)     (None, 7, 7, 192)    0           batch_normalization_144[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_380[0][0]             \n",
      "                                                                 activation_383[0][0]             \n",
      "                                                                 activation_388[0][0]             \n",
      "                                                                 activation_389[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_149 (BatchN (None, 7, 7, 160)    480         conv2d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_394 (Activation)     (None, 7, 7, 160)    0           batch_normalization_149[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)             (None, 7, 7, 160)    179200      activation_394[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_150 (BatchN (None, 7, 7, 160)    480         conv2d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_395 (Activation)     (None, 7, 7, 160)    0           batch_normalization_150[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)             (None, 7, 7, 160)    179200      activation_395[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_146 (BatchN (None, 7, 7, 160)    480         conv2d_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_151 (BatchN (None, 7, 7, 160)    480         conv2d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_391 (Activation)     (None, 7, 7, 160)    0           batch_normalization_146[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_396 (Activation)     (None, 7, 7, 160)    0           batch_normalization_151[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)             (None, 7, 7, 160)    179200      activation_391[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)             (None, 7, 7, 160)    179200      activation_396[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_147 (BatchN (None, 7, 7, 160)    480         conv2d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_152 (BatchN (None, 7, 7, 160)    480         conv2d_152[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_392 (Activation)     (None, 7, 7, 160)    0           batch_normalization_147[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_397 (Activation)     (None, 7, 7, 160)    0           batch_normalization_152[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_15 (AveragePo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)             (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)             (None, 7, 7, 192)    215040      activation_392[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)             (None, 7, 7, 192)    215040      activation_397[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_15[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_145 (BatchN (None, 7, 7, 192)    576         conv2d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_148 (BatchN (None, 7, 7, 192)    576         conv2d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_153 (BatchN (None, 7, 7, 192)    576         conv2d_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_154 (BatchN (None, 7, 7, 192)    576         conv2d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_390 (Activation)     (None, 7, 7, 192)    0           batch_normalization_145[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_393 (Activation)     (None, 7, 7, 192)    0           batch_normalization_148[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_398 (Activation)     (None, 7, 7, 192)    0           batch_normalization_153[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_399 (Activation)     (None, 7, 7, 192)    0           batch_normalization_154[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_390[0][0]             \n",
      "                                                                 activation_393[0][0]             \n",
      "                                                                 activation_398[0][0]             \n",
      "                                                                 activation_399[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_159 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_159 (BatchN (None, 7, 7, 192)    576         conv2d_159[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_404 (Activation)     (None, 7, 7, 192)    0           batch_normalization_159[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_160 (Conv2D)             (None, 7, 7, 192)    258048      activation_404[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_160 (BatchN (None, 7, 7, 192)    576         conv2d_160[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_405 (Activation)     (None, 7, 7, 192)    0           batch_normalization_160[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_156 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_161 (Conv2D)             (None, 7, 7, 192)    258048      activation_405[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_156 (BatchN (None, 7, 7, 192)    576         conv2d_156[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_161 (BatchN (None, 7, 7, 192)    576         conv2d_161[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_401 (Activation)     (None, 7, 7, 192)    0           batch_normalization_156[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_406 (Activation)     (None, 7, 7, 192)    0           batch_normalization_161[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)             (None, 7, 7, 192)    258048      activation_401[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_162 (Conv2D)             (None, 7, 7, 192)    258048      activation_406[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_157 (BatchN (None, 7, 7, 192)    576         conv2d_157[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_162 (BatchN (None, 7, 7, 192)    576         conv2d_162[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_402 (Activation)     (None, 7, 7, 192)    0           batch_normalization_157[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_407 (Activation)     (None, 7, 7, 192)    0           batch_normalization_162[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_16 (AveragePo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)             (None, 7, 7, 192)    258048      activation_402[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_163 (Conv2D)             (None, 7, 7, 192)    258048      activation_407[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_164 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_16[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_155 (BatchN (None, 7, 7, 192)    576         conv2d_155[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_158 (BatchN (None, 7, 7, 192)    576         conv2d_158[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_163 (BatchN (None, 7, 7, 192)    576         conv2d_163[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_164 (BatchN (None, 7, 7, 192)    576         conv2d_164[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_400 (Activation)     (None, 7, 7, 192)    0           batch_normalization_155[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_403 (Activation)     (None, 7, 7, 192)    0           batch_normalization_158[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_408 (Activation)     (None, 7, 7, 192)    0           batch_normalization_163[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_409 (Activation)     (None, 7, 7, 192)    0           batch_normalization_164[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_400[0][0]             \n",
      "                                                                 activation_403[0][0]             \n",
      "                                                                 activation_408[0][0]             \n",
      "                                                                 activation_409[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_167 (Conv2D)             (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_167 (BatchN (None, 7, 7, 192)    576         conv2d_167[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_412 (Activation)     (None, 7, 7, 192)    0           batch_normalization_167[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_168 (Conv2D)             (None, 7, 7, 192)    258048      activation_412[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_168 (BatchN (None, 7, 7, 192)    576         conv2d_168[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_413 (Activation)     (None, 7, 7, 192)    0           batch_normalization_168[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_165 (Conv2D)             (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_169 (Conv2D)             (None, 7, 7, 192)    258048      activation_413[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_165 (BatchN (None, 7, 7, 192)    576         conv2d_165[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_169 (BatchN (None, 7, 7, 192)    576         conv2d_169[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_410 (Activation)     (None, 7, 7, 192)    0           batch_normalization_165[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_414 (Activation)     (None, 7, 7, 192)    0           batch_normalization_169[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_166 (Conv2D)             (None, 3, 3, 320)    552960      activation_410[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_170 (Conv2D)             (None, 3, 3, 192)    331776      activation_414[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_166 (BatchN (None, 3, 3, 320)    960         conv2d_166[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_170 (BatchN (None, 3, 3, 192)    576         conv2d_170[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_411 (Activation)     (None, 3, 3, 320)    0           batch_normalization_166[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_415 (Activation)     (None, 3, 3, 192)    0           batch_normalization_170[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling2D) (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_411[0][0]             \n",
      "                                                                 activation_415[0][0]             \n",
      "                                                                 max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_175 (Conv2D)             (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_175 (BatchN (None, 3, 3, 448)    1344        conv2d_175[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_420 (Activation)     (None, 3, 3, 448)    0           batch_normalization_175[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_172 (Conv2D)             (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_176 (Conv2D)             (None, 3, 3, 384)    1548288     activation_420[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_172 (BatchN (None, 3, 3, 384)    1152        conv2d_172[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_176 (BatchN (None, 3, 3, 384)    1152        conv2d_176[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_417 (Activation)     (None, 3, 3, 384)    0           batch_normalization_172[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_421 (Activation)     (None, 3, 3, 384)    0           batch_normalization_176[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_173 (Conv2D)             (None, 3, 3, 384)    442368      activation_417[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_174 (Conv2D)             (None, 3, 3, 384)    442368      activation_417[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_177 (Conv2D)             (None, 3, 3, 384)    442368      activation_421[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_178 (Conv2D)             (None, 3, 3, 384)    442368      activation_421[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_17 (AveragePo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_171 (Conv2D)             (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_173 (BatchN (None, 3, 3, 384)    1152        conv2d_173[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_174 (BatchN (None, 3, 3, 384)    1152        conv2d_174[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_177 (BatchN (None, 3, 3, 384)    1152        conv2d_177[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_178 (BatchN (None, 3, 3, 384)    1152        conv2d_178[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_179 (Conv2D)             (None, 3, 3, 192)    245760      average_pooling2d_17[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_171 (BatchN (None, 3, 3, 320)    960         conv2d_171[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_418 (Activation)     (None, 3, 3, 384)    0           batch_normalization_173[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_419 (Activation)     (None, 3, 3, 384)    0           batch_normalization_174[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_422 (Activation)     (None, 3, 3, 384)    0           batch_normalization_177[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_423 (Activation)     (None, 3, 3, 384)    0           batch_normalization_178[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_179 (BatchN (None, 3, 3, 192)    576         conv2d_179[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_416 (Activation)     (None, 3, 3, 320)    0           batch_normalization_171[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_418[0][0]             \n",
      "                                                                 activation_419[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 3, 3, 768)    0           activation_422[0][0]             \n",
      "                                                                 activation_423[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_424 (Activation)     (None, 3, 3, 192)    0           batch_normalization_179[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_416[0][0]             \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_3[0][0]              \n",
      "                                                                 activation_424[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_184 (Conv2D)             (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_184 (BatchN (None, 3, 3, 448)    1344        conv2d_184[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_429 (Activation)     (None, 3, 3, 448)    0           batch_normalization_184[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_181 (Conv2D)             (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_185 (Conv2D)             (None, 3, 3, 384)    1548288     activation_429[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_181 (BatchN (None, 3, 3, 384)    1152        conv2d_181[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_185 (BatchN (None, 3, 3, 384)    1152        conv2d_185[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_426 (Activation)     (None, 3, 3, 384)    0           batch_normalization_181[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_430 (Activation)     (None, 3, 3, 384)    0           batch_normalization_185[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_182 (Conv2D)             (None, 3, 3, 384)    442368      activation_426[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_183 (Conv2D)             (None, 3, 3, 384)    442368      activation_426[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_186 (Conv2D)             (None, 3, 3, 384)    442368      activation_430[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_187 (Conv2D)             (None, 3, 3, 384)    442368      activation_430[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_18 (AveragePo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_180 (Conv2D)             (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_182 (BatchN (None, 3, 3, 384)    1152        conv2d_182[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_183 (BatchN (None, 3, 3, 384)    1152        conv2d_183[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_186 (BatchN (None, 3, 3, 384)    1152        conv2d_186[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_187 (BatchN (None, 3, 3, 384)    1152        conv2d_187[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_188 (Conv2D)             (None, 3, 3, 192)    393216      average_pooling2d_18[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_180 (BatchN (None, 3, 3, 320)    960         conv2d_180[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_427 (Activation)     (None, 3, 3, 384)    0           batch_normalization_182[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_428 (Activation)     (None, 3, 3, 384)    0           batch_normalization_183[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_431 (Activation)     (None, 3, 3, 384)    0           batch_normalization_186[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_432 (Activation)     (None, 3, 3, 384)    0           batch_normalization_187[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_188 (BatchN (None, 3, 3, 192)    576         conv2d_188[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_425 (Activation)     (None, 3, 3, 320)    0           batch_normalization_180[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_427[0][0]             \n",
      "                                                                 activation_428[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 3, 3, 768)    0           activation_431[0][0]             \n",
      "                                                                 activation_432[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_433 (Activation)     (None, 3, 3, 192)    0           batch_normalization_188[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_425[0][0]             \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_4[0][0]              \n",
      "                                                                 activation_433[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 21,802,784\n",
      "Trainable params: 21,768,352\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice, how this is a very sophisticated model with more than 21 million parameters (weights) that have been pre-tuned by training the model on millions of images on clusters of thousands of GPUs.\n",
    "\n",
    "The final feature map has shape `(3, 3, 2048)`. That's the feature on top of which we will stick a densely-connected classifier.\n",
    "\n",
    "At this point, we will run the convolutional base over our dataset, recording its output to a Numpy array on disk, then using this data as input to a standalone densely-connected classifier. \n",
    "\n",
    "Let's walk through the code required to set-up the first one: recording the output of `conv_base` on our  data and using these outputs as inputs to a new model.\n",
    "\n",
    "We will start by simply running instances of the previously-introduced `ImageDataGenerator` to extract images as Numpy arrays as well as their labels. We will extract features from these images simply by calling the `predict` method of the `conv_base` model.\n",
    "\n",
    "Before you run the following code snippet, make sure you download the data set `cats_and_dogs_small.rar` from:\n",
    "\n",
    "`I:\\COURSES\\ITP\\BITY3\\IN726-dsmi-data`\n",
    "\n",
    "containing a bunch of images of cats and dogs and point the `base_dir` variable below to the folder where you uncompressed the images.\n",
    "\n",
    "The following code snippet extracts the last output feature map from the InceptionV3 model when we feed it our data of cats and dogs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "base_dir = r\".\\cats_and_dogs_small\"\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "batch_size = 20\n",
    "\n",
    "def extract_features(directory, sample_count):\n",
    "    #Notice that the dimensions of the features variable coincide with the output of the pretrained convnet!!!!!!!\n",
    "    features = np.zeros(shape=(sample_count, 3, 3, 2048)) \n",
    "    labels = np.zeros(shape=(sample_count))\n",
    "    generator = datagen.flow_from_directory(\n",
    "        directory,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "    i = 0\n",
    "    for inputs_batch, labels_batch in generator:\n",
    "        features_batch = conv_base.predict(inputs_batch)\n",
    "        features[i * batch_size : (i + 1) * batch_size] = features_batch\n",
    "        labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n",
    "        i += 1\n",
    "        if i * batch_size >= sample_count:\n",
    "            # Note that since generators yield data indefinitely in a loop,\n",
    "            # we must `break` after every image has been seen once.\n",
    "            break\n",
    "    return features, labels\n",
    "\n",
    "train_features, train_labels = extract_features(train_dir, 100)\n",
    "validation_features, validation_labels = extract_features(validation_dir, 100)\n",
    "test_features, test_labels = extract_features(test_dir, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The extracted features are currently of shape `(samples, 4, 4, 512)`. We will feed them to a densely-connected classifier, so first we must flatten them to `(samples, 8192)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = np.reshape(train_features, (100, 3 * 3 * 2048))\n",
    "validation_features = np.reshape(validation_features, (100, 3 * 3 * 2048))\n",
    "test_features = np.reshape(test_features, (100, 3 * 3 * 2048))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we can define our densely-connected classifier (note the use of dropout for regularization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(256, activation='relu', input_dim=3 * 3 * 2048))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=2e-5),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's train the new model on the data features extracted using the pre-trained convnet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 100 samples, validate on 100 samples\n",
      "Epoch 1/30\n",
      "100/100 [==============================] - 6s 64ms/step - loss: 1.2964 - acc: 0.6300 - val_loss: 0.2282 - val_acc: 0.9000\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 0s 682us/step - loss: 0.4412 - acc: 0.8500 - val_loss: 0.1658 - val_acc: 0.9500\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 0s 683us/step - loss: 0.1404 - acc: 0.9300 - val_loss: 0.1503 - val_acc: 0.9400\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 0s 663us/step - loss: 0.1224 - acc: 0.9500 - val_loss: 0.1606 - val_acc: 0.9400\n",
      "Epoch 5/30\n",
      "100/100 [==============================] - 0s 836us/step - loss: 0.0622 - acc: 0.9900 - val_loss: 0.1293 - val_acc: 0.9400\n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 0s 832us/step - loss: 0.1401 - acc: 0.9600 - val_loss: 0.1216 - val_acc: 0.9300\n",
      "Epoch 7/30\n",
      "100/100 [==============================] - 0s 663us/step - loss: 0.0749 - acc: 0.9600 - val_loss: 0.1299 - val_acc: 0.9400\n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 0s 837us/step - loss: 0.0248 - acc: 1.0000 - val_loss: 0.1185 - val_acc: 0.9400\n",
      "Epoch 9/30\n",
      "100/100 [==============================] - 0s 678us/step - loss: 0.0371 - acc: 1.0000 - val_loss: 0.1218 - val_acc: 0.9400\n",
      "Epoch 10/30\n",
      "100/100 [==============================] - 0s 827us/step - loss: 0.0384 - acc: 0.9800 - val_loss: 0.1207 - val_acc: 0.9400\n",
      "Epoch 11/30\n",
      "100/100 [==============================] - 0s 668us/step - loss: 0.0136 - acc: 1.0000 - val_loss: 0.1571 - val_acc: 0.9300\n",
      "Epoch 12/30\n",
      "100/100 [==============================] - 0s 676us/step - loss: 0.0192 - acc: 1.0000 - val_loss: 0.1080 - val_acc: 0.9400\n",
      "Epoch 13/30\n",
      "100/100 [==============================] - 0s 823us/step - loss: 0.0110 - acc: 1.0000 - val_loss: 0.1118 - val_acc: 0.9600\n",
      "Epoch 14/30\n",
      "100/100 [==============================] - 0s 685us/step - loss: 0.0097 - acc: 1.0000 - val_loss: 0.1529 - val_acc: 0.9400\n",
      "Epoch 15/30\n",
      "100/100 [==============================] - 0s 808us/step - loss: 0.0173 - acc: 0.9900 - val_loss: 0.1083 - val_acc: 0.9700\n",
      "Epoch 16/30\n",
      "100/100 [==============================] - 0s 682us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.1006 - val_acc: 0.9600\n",
      "Epoch 17/30\n",
      "100/100 [==============================] - 0s 814us/step - loss: 0.0249 - acc: 0.9900 - val_loss: 0.1153 - val_acc: 0.9500\n",
      "Epoch 18/30\n",
      "100/100 [==============================] - 0s 702us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.1125 - val_acc: 0.9500\n",
      "Epoch 19/30\n",
      "100/100 [==============================] - 0s 813us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.1132 - val_acc: 0.9400\n",
      "Epoch 20/30\n",
      "100/100 [==============================] - 0s 668us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.1126 - val_acc: 0.9500\n",
      "Epoch 21/30\n",
      "100/100 [==============================] - 0s 832us/step - loss: 0.0092 - acc: 1.0000 - val_loss: 0.1177 - val_acc: 0.9500\n",
      "Epoch 22/30\n",
      "100/100 [==============================] - 0s 695us/step - loss: 0.0059 - acc: 1.0000 - val_loss: 0.1013 - val_acc: 0.9800\n",
      "Epoch 23/30\n",
      "100/100 [==============================] - 0s 805us/step - loss: 0.0067 - acc: 1.0000 - val_loss: 0.1056 - val_acc: 0.9400\n",
      "Epoch 24/30\n",
      "100/100 [==============================] - 0s 668us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.1314 - val_acc: 0.9400\n",
      "Epoch 25/30\n",
      "100/100 [==============================] - 0s 675us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.1027 - val_acc: 0.9500\n",
      "Epoch 26/30\n",
      "100/100 [==============================] - 0s 704us/step - loss: 0.0157 - acc: 0.9900 - val_loss: 0.2092 - val_acc: 0.9300\n",
      "Epoch 27/30\n",
      "100/100 [==============================] - 0s 634us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.1310 - val_acc: 0.9400\n",
      "Epoch 28/30\n",
      "100/100 [==============================] - 0s 874us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.1112 - val_acc: 0.9600\n",
      "Epoch 29/30\n",
      "100/100 [==============================] - 0s 808us/step - loss: 2.6781e-04 - acc: 1.0000 - val_loss: 0.1109 - val_acc: 0.9600\n",
      "Epoch 30/30\n",
      "100/100 [==============================] - 0s 808us/step - loss: 6.2122e-04 - acc: 1.0000 - val_loss: 0.1319 - val_acc: 0.9400\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_features, train_labels,\n",
    "                    epochs=30,\n",
    "                    batch_size=20,\n",
    "                    validation_data=(validation_features, validation_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training is very fast, since we only have to deal with two `Dense` layers -- an epoch takes less than one second even on CPU.\n",
    "\n",
    "Let's take a look at the loss and accuracy curves during training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We reach a validation accuracy of around 94%, much better than what we could achieve training from scratch with so little data (as we did in the previous practical were accuracy without data augmentation was on the low 70s). \n",
    "Finally, let's print the accuracy of our model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 748us/step\n"
     ]
    }
   ],
   "source": [
    "[loss, accuracy] = model.evaluate(test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.92\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about that? you just created a machine vision system able to discriminate cats from dogs in digital images with almost perfect accuracy!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu2",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
