{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To proceed with this tutorial, make sure you have a working installation of tensorflow and Keras in your machine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!conda install keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If that doesn't work, check out https://keras.io/#installation for details on proper installation.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to convnets using Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's import the Keras deep learning library that provides us with a convenient interface to TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.4'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let's take a practical look at a very simple convnet example. We will use our convnet to classify MNIST digits, a task that you've already done in previous Practicals, using logistic regression and a densely-connected neural network. Even though our convnet will be very basic, its accuracy will still blow out of the water that of the densely-connected model from the TensorFlow practical.\n",
    "\n",
    "![](./images/mnist.png)\n",
    "\n",
    "Our workflow will be as follow: first we will present our neural network with the `training data`, `train_images` and `train_labels`. The network will then learn to associate images and labels. Finally, we will ask the network to produce predictions for `test_images`, and we will verify if these predictions match the labels from `test_labels`.\n",
    "\n",
    "Let's build our network.\n",
    "\n",
    "The 6 lines of code below show you what a basic convnet looks like in Keras. It's a stack of `Conv2D` and `MaxPooling2D` layers. Importantly, a convnet takes as input tensors of shape `(image_height, image_width, image_channels)` (not including the batch dimension containing the different samples in the data set). In our case, we will configure our convnet to process inputs of size `(28, 28, 1)`, which is the format of MNIST images. We do this via passing the argument `input_shape=(28, 28, 1)` to our first layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "#The next layer is design to have 32 channels (kernesl) in depth of size 3x3.\n",
    "#The activation function is said to be A rectifier Linear unit (Relu)\n",
    "#The input to the layer are 28 x 28 grayscale images\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1))) \n",
    "#now we add a Max pooling layer of size 2x2\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "#Another convolutional layer, this one with 64 kernels\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "#and another Max pooling\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "#And another convolution\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's display the architecture of our convnet so far:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "=================================================================\n",
      "Total params: 55,744\n",
      "Trainable params: 55,744\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "You can see above that the output of every `Conv2D` and `MaxPooling2D` layer is a 3D tensor of shape `(height, width, channels)`. The width \n",
    "and height dimensions tend to shrink as we go deeper in the network. The number of channels is controlled by the first argument passed to \n",
    "the `Conv2D` layers (e.g. 32 or 64).\n",
    "\n",
    "The next step would be to feed our last output tensor (of shape `(3, 3, 64)`) into a densely-connected classifier network like those you are already familiar with: a stack of `Dense` layers. These classifiers process vectors, which are 1D, whereas our current output is a 3D tensor. So first, we will have to flatten our 3D outputs to 1D, and then add a few `Dense` layers on top:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to do 10-class classification (digits 0-9), so we use a final layer with 10 outputs and a softmax activation. Now here's what our network looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                36928     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, our `(3, 3, 64)` outputs were flattened into vectors of shape `(576,)`, before going through two `Dense` layers.\n",
    "\n",
    "Notice that this very simple network has more than 93,000 parameters (weights) to be tuned during training.\n",
    "\n",
    "Before training, we will preprocess our data by reshaping it into the shape that the network expects, and scaling it so that all values are in the [0, 1] interval. Previously, our training images for instance were stored in flat arrays of shape (60000, 28* 28) of type uint8 with values in the [0, 255] interval. We transform it into a float32 array of shape (60000, 28, 28) with values between 0 and 1. Hence, notice that with convolutional networks we can exploit the 2 dimensional structure contained in images and therefore we should avoid flattening the input images.\n",
    "\n",
    "We also need to divide the entire data set into a training and testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's normalize the input data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "test_images = test_images.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the first 10 labels in the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This vector of target values indicates that the first image in the training set is a 5, the second is a 0, the third is a 4, etc.\n",
    "\n",
    "We need to categorically encode the labels. To vectorize the labels, there are two possibilities: we could just cast the label list as an integer tensor, or we could use a \"one-hot\" encoding. One-hot encoding is a widely used format for categorical data, also called \"categorical encoding\". Note that there is a built-in way to do this in Keras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "train_labels[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a one-hot encoding of our labels, again indicating that the first image in the training set is a 5, the second is a 0, the third is a 4, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make our network ready for training, we need to pick three more things, as part of a \"compilation\" step:\n",
    "\n",
    "* A loss function: the is how the network will be able to measure how good a job it is doing on its training data, and thus how it will be \n",
    "able to steer itself in the right direction.\n",
    "* An optimizer: this is the mechanism through which the network will update itself based on the data it sees and its loss function (`rmsprop` is a variation of the gradient descent algorithm we are used to). \n",
    "* Metrics to monitor during training and testing. Here we will only care about accuracy (the fraction of the images that were correctly \n",
    "classified).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's train our convnet on the MNIST digits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\drozado\\miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 24s 399us/step - loss: 0.1669 - acc: 0.9473\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 23s 382us/step - loss: 0.0486 - acc: 0.9847\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 23s 387us/step - loss: 0.0333 - acc: 0.9895\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 23s 387us/step - loss: 0.0267 - acc: 0.9921\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 23s 385us/step - loss: 0.0197 - acc: 0.9940\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ea163576a0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, epochs=5, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's evaluate the model on the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 138us/step\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9925"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our densely-connected network using TensorFlow had a test accuracy of 97%, our basic convolutional network has a test accuracy above  99%: we decreased our error rate by more than 60% (relative). Not bad! I hope this demonstration illustrates that convolutional networks are the proper way to go for machine vision problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph of your model\n",
    "plot_model(): plots your graph in a nice layout. You can even save it as \".png\" using SVG(). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "plot_model(model,to_file='myFirstConvolutionalNeuralNetworkModel.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also directly obtain the `pydot.Graph` object and render it yourself, for example to show it in an ipython notebook :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"629pt\" viewBox=\"0.00 0.00 217.00 629.00\" width=\"217pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 625)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-625 213,-625 213,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 2104906131944 -->\n",
       "<g class=\"node\" id=\"node1\"><title>2104906131944</title>\n",
       "<polygon fill=\"none\" points=\"41,-511.5 41,-547.5 168,-547.5 168,-511.5 41,-511.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"104.5\" y=\"-525.8\">conv2d_4: Conv2D</text>\n",
       "</g>\n",
       "<!-- 2104906130544 -->\n",
       "<g class=\"node\" id=\"node2\"><title>2104906130544</title>\n",
       "<polygon fill=\"none\" points=\"0,-438.5 0,-474.5 209,-474.5 209,-438.5 0,-438.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"104.5\" y=\"-452.8\">max_pooling2d_3: MaxPooling2D</text>\n",
       "</g>\n",
       "<!-- 2104906131944&#45;&gt;2104906130544 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>2104906131944-&gt;2104906130544</title>\n",
       "<path d=\"M104.5,-511.313C104.5,-503.289 104.5,-493.547 104.5,-484.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"108,-484.529 104.5,-474.529 101,-484.529 108,-484.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2104906131832 -->\n",
       "<g class=\"node\" id=\"node3\"><title>2104906131832</title>\n",
       "<polygon fill=\"none\" points=\"41,-365.5 41,-401.5 168,-401.5 168,-365.5 41,-365.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"104.5\" y=\"-379.8\">conv2d_5: Conv2D</text>\n",
       "</g>\n",
       "<!-- 2104906130544&#45;&gt;2104906131832 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>2104906130544-&gt;2104906131832</title>\n",
       "<path d=\"M104.5,-438.313C104.5,-430.289 104.5,-420.547 104.5,-411.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"108,-411.529 104.5,-401.529 101,-411.529 108,-411.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2104906131104 -->\n",
       "<g class=\"node\" id=\"node4\"><title>2104906131104</title>\n",
       "<polygon fill=\"none\" points=\"0,-292.5 0,-328.5 209,-328.5 209,-292.5 0,-292.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"104.5\" y=\"-306.8\">max_pooling2d_4: MaxPooling2D</text>\n",
       "</g>\n",
       "<!-- 2104906131832&#45;&gt;2104906131104 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>2104906131832-&gt;2104906131104</title>\n",
       "<path d=\"M104.5,-365.313C104.5,-357.289 104.5,-347.547 104.5,-338.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"108,-338.529 104.5,-328.529 101,-338.529 108,-338.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2104906104056 -->\n",
       "<g class=\"node\" id=\"node5\"><title>2104906104056</title>\n",
       "<polygon fill=\"none\" points=\"41,-219.5 41,-255.5 168,-255.5 168,-219.5 41,-219.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"104.5\" y=\"-233.8\">conv2d_6: Conv2D</text>\n",
       "</g>\n",
       "<!-- 2104906131104&#45;&gt;2104906104056 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>2104906131104-&gt;2104906104056</title>\n",
       "<path d=\"M104.5,-292.313C104.5,-284.289 104.5,-274.547 104.5,-265.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"108,-265.529 104.5,-255.529 101,-265.529 108,-265.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2104906140808 -->\n",
       "<g class=\"node\" id=\"node6\"><title>2104906140808</title>\n",
       "<polygon fill=\"none\" points=\"50,-146.5 50,-182.5 159,-182.5 159,-146.5 50,-146.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"104.5\" y=\"-160.8\">flatten_1: Flatten</text>\n",
       "</g>\n",
       "<!-- 2104906104056&#45;&gt;2104906140808 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>2104906104056-&gt;2104906140808</title>\n",
       "<path d=\"M104.5,-219.313C104.5,-211.289 104.5,-201.547 104.5,-192.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"108,-192.529 104.5,-182.529 101,-192.529 108,-192.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2104906138176 -->\n",
       "<g class=\"node\" id=\"node7\"><title>2104906138176</title>\n",
       "<polygon fill=\"none\" points=\"52.5,-73.5 52.5,-109.5 156.5,-109.5 156.5,-73.5 52.5,-73.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"104.5\" y=\"-87.8\">dense_1: Dense</text>\n",
       "</g>\n",
       "<!-- 2104906140808&#45;&gt;2104906138176 -->\n",
       "<g class=\"edge\" id=\"edge7\"><title>2104906140808-&gt;2104906138176</title>\n",
       "<path d=\"M104.5,-146.313C104.5,-138.289 104.5,-128.547 104.5,-119.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"108,-119.529 104.5,-109.529 101,-119.529 108,-119.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2104906140080 -->\n",
       "<g class=\"node\" id=\"node8\"><title>2104906140080</title>\n",
       "<polygon fill=\"none\" points=\"52.5,-0.5 52.5,-36.5 156.5,-36.5 156.5,-0.5 52.5,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"104.5\" y=\"-14.8\">dense_2: Dense</text>\n",
       "</g>\n",
       "<!-- 2104906138176&#45;&gt;2104906140080 -->\n",
       "<g class=\"edge\" id=\"edge8\"><title>2104906138176-&gt;2104906140080</title>\n",
       "<path d=\"M104.5,-73.3129C104.5,-65.2895 104.5,-55.5475 104.5,-46.5691\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"108,-46.5288 104.5,-36.5288 101,-46.5289 108,-46.5288\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2104906131440 -->\n",
       "<g class=\"node\" id=\"node9\"><title>2104906131440</title>\n",
       "<polygon fill=\"none\" points=\"52.5,-584.5 52.5,-620.5 156.5,-620.5 156.5,-584.5 52.5,-584.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"104.5\" y=\"-598.8\">2104906131440</text>\n",
       "</g>\n",
       "<!-- 2104906131440&#45;&gt;2104906131944 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>2104906131440-&gt;2104906131944</title>\n",
       "<path d=\"M104.5,-584.313C104.5,-576.289 104.5,-566.547 104.5,-557.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"108,-557.529 104.5,-547.529 101,-557.529 108,-557.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
