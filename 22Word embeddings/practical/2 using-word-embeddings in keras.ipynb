{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.2.4'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using one-hot encoding text in Keras\n",
    "\n",
    "One-hot encoding is the most common, most basic way to turn a token into a vector. You already saw it in action in our initial IMDB example (done with words, in our case). It consists on associating a unique integer index to every word, then turning this integer index $i$ into a binary vector of size $N$, the size of the vocabulary, that would be all-zeros except for the i-th entry, which would be 1.\n",
    "\n",
    "Note that Keras has built-in utilities for doing one-hot encoding text at the word level, starting from raw text data. This is what you should actually be using, as it will take care of a number of important features, such as stripping special characters from strings, or only taking into the top N most common words in your dataset (a common restriction to avoid dealing with very large input vector spaces).\n",
    "\n",
    "Using Keras for word-level one-hot encoding begins by tokenizing the text (mapping a corpus of text into a list of IDs):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3, 4, 1, 5], [1, 6, 7, 8, 9]]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.text import one_hot\n",
    "\n",
    "samples = ['The cat sat on the mat.', 'The dog ate my homework.']\n",
    "\n",
    "# We create a tokenizer, configured to only take into account the top-10 most common words\n",
    "tokenizer = Tokenizer(num_words=10)\n",
    "\n",
    "# This builds the word index\n",
    "tokenizer.fit_on_texts(samples)\n",
    "\n",
    "# This turns strings into lists of integer indices.\n",
    "sequences = tokenizer.texts_to_sequences(samples)\n",
    "sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the word \"The\" for instance has been mapped to the index 1 and the word dog has been mapped to the index 6.\n",
    "This is how you can recover the word index that was computed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9 unique tokens.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'the': 1,\n",
       " 'cat': 2,\n",
       " 'sat': 3,\n",
       " 'on': 4,\n",
       " 'mat': 5,\n",
       " 'dog': 6,\n",
       " 'ate': 7,\n",
       " 'my': 8,\n",
       " 'homework': 9}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we transform the sequences of indexes into sequences of One hot encoded vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One hot encoded version of: The cat sat on the mat. [1, 2, 3, 4, 1, 5]\n",
      "[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n",
      "One hot encoded version of: The dog ate my homework. [1, 6, 7, 8, 9]\n",
      "[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "maxID = max(map(lambda x: max(x), sequences))\n",
    "for i,s in enumerate(sequences):\n",
    "    print(\"One hot encoded version of:\", samples[i], s)\n",
    "    data = s\n",
    "    data = array(data)\n",
    "    # one hot encode\n",
    "    encoded = to_categorical(data,num_classes=maxID+1)\n",
    "    print(encoded)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you understand the one hot encoded representation of our original sequences of text.\n",
    "\n",
    "---\n",
    "\n",
    "One hot encoding of text is extremely wasteful when you're working with large vocabularies. Remember that the length of the vectors is the size of the vocabulary, and every element in the vector will be a 0 except for one element that contains a 1.\n",
    "\n",
    "Keras allows us to transform text into a more compact representation of a matrix in which each row represents a sentence and each column represents the index associated with the word. If a word is appears in a sentence, the column representing the word in the matrix will have an entry of 1.\n",
    "\n",
    "Recall that we have previously transform two sentences of text into list of IDs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The cat sat on the mat.', 'The dog ate my homework.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3, 4, 1, 5], [1, 6, 7, 8, 9]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print( samples )\n",
    "sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now transform this representation into a compact matrix. Recall that each row represents a sentence and each column represents a word in our vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_results = tokenizer.texts_to_matrix(samples, mode='binary')\n",
    "one_hot_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using word embeddings in Keras\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Another popular and powerful way to associate a vector with a word is the use of dense \"word vectors\", also called \"word embeddings\". \n",
    "While the vectors obtained through one-hot encoding are binary, sparse (mostly made of zeros) and very high-dimensional (same dimensionality as the \n",
    "number of words in the vocabulary), \"word embeddings\" are low-dimensional floating point vectors \n",
    "(i.e. \"dense\" vectors, as opposed to sparse vectors). \n",
    "Unlike word vectors obtained via one-hot encoding, word embeddings are learned from data. \n",
    "It is common to see word embeddings that are 256-dimensional, 512-dimensional, or 1024-dimensional when dealing with very large vocabularies. \n",
    "On the other hand, one-hot encoding words generally leads to vectors that are 20,000-dimensional or higher (capturing a vocabulary of 20,000 \n",
    "token in this case). So, word embeddings pack more information into far fewer dimensions. \n",
    "\n",
    "<img src=\"./images/ohVSwe.png\" style=\"width: 400px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two ways to obtain word embeddings:\n",
    "\n",
    "* Learn word embeddings jointly with the main task you care about (e.g. document classification, sentiment prediction,...). \n",
    "In this setup, you would start with random word vectors, then learn your word vectors in the same way that you learn the weights of a neural network.\n",
    "* Load into your model word embeddings that were pre-computed using a different machine learning task than the one you are trying to solve. \n",
    "These are called \"pre-trained word embeddings\". \n",
    "\n",
    "Let's take a look at both."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning word embeddings with the `Embedding` layer\n",
    "\n",
    "\n",
    "The simplest way to associate a dense vector to a word would be to pick the vector at random. The problem with this approach is that the \n",
    "resulting embedding space would have no structure: for instance, the words \"accurate\" and \"exact\" may end up with completely different \n",
    "embeddings, even though they are interchangeable in most sentences. It would be very difficult for a deep neural network to make sense of \n",
    "such a noisy, unstructured embedding space. \n",
    "\n",
    "To get a bit more abstract: the geometric relationships between word vectors should reflect the semantic relationships between these words. \n",
    "Word embeddings are meant to map human language into a geometric space. For instance, in a reasonable embedding space, we would expect \n",
    "synonyms to be embedded into similar word vectors, and in general we would expect the geometric distance (e.g. L2 distance or the cosine similarity) between any two \n",
    "word vectors to relate to the semantic distance of the associated words (words meaning very different things would be embedded to points \n",
    "far away from each other, while related words would be closer). Even beyond mere distance, we may want specific __directions__ in the \n",
    "embedding space to be meaningful. \n",
    "\n",
    "Is there some \"ideal\" word embedding space that would perfectly map human language and could be used for any natural language processing \n",
    "task? Possibly, but in any case, we have yet to compute anything of the sort. Also, there isn't such a thing as \"human language\", there are \n",
    "many different languages and they are not isomorphic, as a language is the reflection of a specific culture and a specific context. But more \n",
    "pragmatically, what makes a good word embedding space depends heavily on your task: the perfect word embedding space for an \n",
    "English-language movie review sentiment analysis model may look very different from the perfect embedding space for an English-language \n",
    "legal document classification model, because the importance of certain semantic relationships varies from task to task.\n",
    "\n",
    "It is thus reasonable to __learn__ a new embedding space with every new task. Thankfully, backpropagation makes this really easy, and Keras makes it \n",
    "even easier. It's just about learning the weights of a layer: the `Embedding` layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding\n",
    "\n",
    "# The Embedding layer takes at least two arguments:\n",
    "# the number of possible tokens (vocabulary size), here 1000 (1 + maximum word index),\n",
    "# and the dimensionality of the embeddings, here 64.\n",
    "embedding_layer = Embedding(1000, 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The `Embedding` layer is best understood as a dictionary mapping integer indices (which stand for specific words) to dense vectors. It takes \n",
    "as input integers, it looks up these integers into an internal dictionary, and it returns the associated vectors (word embeddings). It's effectively a dictionary lookup."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Embedding` layer takes as input a 2D tensor of integers, of shape `(samples, sequence_length)`, where each entry is a sequence of \n",
    "integers. It can embed sequences of variable lengths, so for instance we could feed into our embedding layer above batches that could have \n",
    "shapes `(32, 10)` (batch of 32 sequences of length 10) or `(64, 15)` (batch of 64 sequences of length 15). All sequences in a batch must \n",
    "have the same length, though (since we need to pack them into a single tensor), so sequences that are shorter than others should be padded \n",
    "with zeros, and sequences that are longer should be truncated.\n",
    "\n",
    "This layer returns a 3D floating point tensor, of shape `(samples, sequence_length, embedding_dimensionality)`. Such a 3D tensor can then \n",
    "be processed by a neural network.\n",
    "\n",
    "When you instantiate an `Embedding` layer, its weights (its internal dictionary of token vectors) are initially random, just like with any \n",
    "other layer. During training, these word vectors will be gradually adjusted via backpropagation, structuring the space into something that the \n",
    "downstream model can exploit. Once fully trained, your embedding space will show a lot of structure -- a kind of structure specialized for \n",
    "the specific problem you were training your model for.\n",
    "\n",
    "Let's apply this idea to the IMDB movie review sentiment prediction task that you are already familiar with. Let's quickly prepare the data. We will restrict the movie reviews to the top 10,000 most common words (like we did the first time we worked with this dataset), and cut the reviews after only 120 words. Our network will simply learn 8-dimensional embeddings for each of the 10,000 words, turn the input integer sequences (2D integer tensor) into embedded sequences (3D float tensor), flatten the tensor to 2D, and train a single `Dense` layer on top for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras import preprocessing\n",
    "\n",
    "# Number of words to consider as features (i.e. vocabulary size)\n",
    "max_features = 10000\n",
    "# Cut texts after this number of words \n",
    "# (among top max_features most common words)\n",
    "maxlen = 120\n",
    "\n",
    "# Load the data as lists of integers.\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "\n",
    "# This turns our lists of integers\n",
    "# into a 2D integer tensor of shape `(samples, maxlen)` \n",
    "# Padded with zeros if sentence has less than 120 words\n",
    "x_train = preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = preprocessing.sequence.pad_sequences(x_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take a look to the first two reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5244,   16,  480,   66, 3785,   33,    4,  130,   12,   16,   38,\n",
       "         619,    5,   25,  124,   51,   36,  135,   48,   25, 1415,   33,\n",
       "           6,   22,   12,  215,   28,   77,   52,    5,   14,  407,   16,\n",
       "          82,    2,    8,    4,  107,  117, 5952,   15,  256,    4,    2,\n",
       "           7, 3766,    5,  723,   36,   71,   43,  530,  476,   26,  400,\n",
       "         317,   46,    7,    4,    2, 1029,   13,  104,   88,    4,  381,\n",
       "          15,  297,   98,   32, 2071,   56,   26,  141,    6,  194, 7486,\n",
       "          18,    4,  226,   22,   21,  134,  476,   26,  480,    5,  144,\n",
       "          30, 5535,   18,   51,   36,   28,  224,   92,   25,  104,    4,\n",
       "         226,   65,   16,   38, 1334,   88,   12,   16,  283,    5,   16,\n",
       "        4472,  113,  103,   32,   15,   16, 5345,   19,  178,   32],\n",
       "       [   5,   89,   29,  952,   46,   37,    4,  455,    9,   45,   43,\n",
       "          38, 1543, 1905,  398,    4, 1649,   26, 6853,    5,  163,   11,\n",
       "        3215,    2,    4, 1153,    9,  194,  775,    7, 8255,    2,  349,\n",
       "        2637,  148,  605,    2, 8003,   15,  123,  125,   68,    2, 6853,\n",
       "          15,  349,  165, 4362,   98,    5,    4,  228,    9,   43,    2,\n",
       "        1157,   15,  299,  120,    5,  120,  174,   11,  220,  175,  136,\n",
       "          50,    9, 4373,  228, 8255,    5,    2,  656,  245, 2350,    5,\n",
       "           4, 9837,  131,  152,  491,   18,    2,   32, 7464, 1212,   14,\n",
       "           9,    6,  371,   78,   22,  625,   64, 1382,    9,    8,  168,\n",
       "         145,   23,    4, 1690,   15,   16,    4, 1355,    5,   28,    6,\n",
       "          52,  154,  462,   33,   89,   78,  285,   16,  145,   95]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create our model. Notice the embedding layer at the base of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "# We specify the maximum input length to our Embedding layer\n",
    "# so we can later flatten the embedded inputs\n",
    "model.add(Embedding(10000, 8, input_length=maxlen))\n",
    "# After the Embedding layer, \n",
    "# our activations have shape `(samples, maxlen, 8)`.\n",
    "\n",
    "# We flatten the 3D tensor of embeddings \n",
    "# into a 2D tensor of shape `(samples, maxlen * 8)`\n",
    "model.add(Flatten())\n",
    "# We add the classifier on top\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 120, 8)            80000     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 960)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 961       \n",
      "=================================================================\n",
      "Total params: 80,961\n",
      "Trainable params: 80,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 1s 37us/step - loss: 0.6037 - acc: 0.6974 - val_loss: 0.4346 - val_acc: 0.8234\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 1s 29us/step - loss: 0.3436 - acc: 0.8626 - val_loss: 0.3292 - val_acc: 0.8604\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 1s 29us/step - loss: 0.2684 - acc: 0.8904 - val_loss: 0.3112 - val_acc: 0.8670\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 1s 29us/step - loss: 0.2345 - acc: 0.9055 - val_loss: 0.3105 - val_acc: 0.8724\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 1s 29us/step - loss: 0.2115 - acc: 0.9161 - val_loss: 0.3115 - val_acc: 0.8750\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 1s 29us/step - loss: 0.1930 - acc: 0.9257 - val_loss: 0.3178 - val_acc: 0.8720\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 1s 28us/step - loss: 0.1751 - acc: 0.9337 - val_loss: 0.3254 - val_acc: 0.8726\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 1s 29us/step - loss: 0.1589 - acc: 0.9410 - val_loss: 0.3326 - val_acc: 0.8702\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 1s 28us/step - loss: 0.1423 - acc: 0.9485 - val_loss: 0.3430 - val_acc: 0.8670\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 1s 29us/step - loss: 0.1262 - acc: 0.9555 - val_loss: 0.3528 - val_acc: 0.8648\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get to a validation accuracy of ~86%, which is pretty good. But note that merely flattening the embedded sequences and training a single `Dense` layer on top leads to a model that treats each word in the input sequence separately, without considering inter-word relationships and structure sentence (e.g. it would likely treat both *\"this movie is shit\"* and *\"this movie is the shit\"* as being negative \"reviews\"). It would be much better to add recurrent layers on top of the embedded sequences to learn features that take into account each sequence as a whole. Such a recurrent neural network with memory of the past will be the topic of future lectures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When not enough data is available\n",
    "\n",
    "Notice that we have been using lots of data for creating a good model. The previous model was trained on 20,000 movie reviews. What would happen if we would have much less data, like only 200 reviews?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 120, 8)            80000     \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 960)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 961       \n",
      "=================================================================\n",
      "Total params: 80,961\n",
      "Trainable params: 80,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/10\n",
      "160/160 [==============================] - 0s 957us/step - loss: 0.6897 - acc: 0.5625 - val_loss: 0.6924 - val_acc: 0.5250\n",
      "Epoch 2/10\n",
      "160/160 [==============================] - 0s 44us/step - loss: 0.6636 - acc: 0.8875 - val_loss: 0.6919 - val_acc: 0.4750\n",
      "Epoch 3/10\n",
      "160/160 [==============================] - 0s 44us/step - loss: 0.6437 - acc: 0.9562 - val_loss: 0.6913 - val_acc: 0.5250\n",
      "Epoch 4/10\n",
      "160/160 [==============================] - 0s 37us/step - loss: 0.6249 - acc: 0.9750 - val_loss: 0.6909 - val_acc: 0.4250\n",
      "Epoch 5/10\n",
      "160/160 [==============================] - 0s 44us/step - loss: 0.6058 - acc: 0.9750 - val_loss: 0.6905 - val_acc: 0.4250\n",
      "Epoch 6/10\n",
      "160/160 [==============================] - 0s 37us/step - loss: 0.5858 - acc: 0.9750 - val_loss: 0.6901 - val_acc: 0.4250\n",
      "Epoch 7/10\n",
      "160/160 [==============================] - 0s 44us/step - loss: 0.5649 - acc: 0.9750 - val_loss: 0.6898 - val_acc: 0.4500\n",
      "Epoch 8/10\n",
      "160/160 [==============================] - 0s 37us/step - loss: 0.5430 - acc: 0.9750 - val_loss: 0.6896 - val_acc: 0.4750\n",
      "Epoch 9/10\n",
      "160/160 [==============================] - 0s 44us/step - loss: 0.5207 - acc: 0.9750 - val_loss: 0.6893 - val_acc: 0.5000\n",
      "Epoch 10/10\n",
      "160/160 [==============================] - 0s 37us/step - loss: 0.4976 - acc: 0.9750 - val_loss: 0.6891 - val_acc: 0.5000\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense\n",
    "\n",
    "del model #Delete the previous model\n",
    "model = Sequential()\n",
    "# We specify the maximum input length to our Embedding layer\n",
    "# so we can later flatten the embedded inputs\n",
    "model.add(Embedding(10000, 8, input_length=maxlen))\n",
    "# After the Embedding layer, \n",
    "# our activations have shape `(samples, maxlen, 8)`.\n",
    "\n",
    "# We flatten the 3D tensor of embeddings \n",
    "# into a 2D tensor of shape `(samples, maxlen * 8)`\n",
    "model.add(Flatten())\n",
    "\n",
    "# We add the classifier on top\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "model.summary()\n",
    "\n",
    "#Notice that we only use the first 200 instances in our data set for training\n",
    "history = model.fit(x_train[:200], y_train[:200],\n",
    "                    epochs=10,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With very little training data available, our model doesn't learn much. The validation accuracy is around 50%, the same that we would get with random guessing the sentiment of a movie. Note that your mileage may vary: since we have so few training samples, performance is heavily dependent on which exact 200 samples we picked."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using pre-trained word embeddings\n",
    "\n",
    "\n",
    "What to do then when you have so little training data available that could never use your data alone to learn an appropriate task-specific embedding of your vocabulary. \n",
    "\n",
    "Instead of learning word embeddings jointly with the problem you want to solve, you could be loading embedding vectors from a pre-computed embedding space known to be highly structured and to exhibit useful properties -- that captures generic aspects of language structure. The rationale behind using pre-trained word embeddings in natural language processing is very much the same as for using pre-trained convnets in image classification: we don't have enough data available to learn truly powerful features on our own, but we expect the features that we need to be fairly generic, i.e. common visual features or semantic features. In this case it makes sense to reuse features learned on a different problem.\n",
    "\n",
    "There are various pre-computed databases of word embeddings that can download and start using in a Keras `Embedding` layer. Word2Vec is one of them. \n",
    "\n",
    "Let's take a look at how you can get started using word2vec embeddings in a Keras model. We will also use this example to refresh the text tokenization techniques we introduced a few paragraphs ago: we will start from raw text, and work our way up.\n",
    "\n",
    "Load the word2vec word embeddings by simply pointing towards the location of the model file in your computer. You can find a trained word2vec model `GoogleNews-vectors-negative300.bin` at: `I:\\COURSES\\ITP\\BITY3\\IN726-dsmi-data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\drozado\\miniconda3\\lib\\site-packages\\gensim\\utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "filename = './GoogleNews-vectors-negative300.bin' \n",
    "modelwv = KeyedVectors.load_word2vec_format(filename, binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's transform the word2vec model data structure `modelwv` into a numpy matrix that keras can understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "embedding_dim = modelwv.vector_size\n",
    "max_words = 10000  # We will only consider the top 10,000 words in the dataset\n",
    "# convert the wv word vectors into a numpy matrix that is suitable for insertion\n",
    "# into our TensorFlow and Keras models\n",
    "embedding_matrix = np.zeros((max_words, embedding_dim))\n",
    "for i in range(max_words):\n",
    "    embedding_vector = modelwv[modelwv.index2word[i]]\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a model\n",
    "\n",
    "We will be using the same model architecture as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 120, 300)          3000000   \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 36000)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 36001     \n",
      "=================================================================\n",
      "Total params: 3,036,001\n",
      "Trainable params: 3,036,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten, Dense\n",
    "\n",
    "del model #Delete previous model\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_words, embedding_dim, input_length=maxlen))\n",
    "model.add(Flatten())\n",
    "#model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the word2vec embeddings in the model\n",
    "\n",
    "\n",
    "The `Embedding` layer has a single weight matrix: a 2D float matrix where each entry `i` is the word vector meant to be associated with index `i`. Simple enough. Let's just load the word2vec matrix we prepared `embedding_matrix` into our `Embedding` layer, the first layer in our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[0].set_weights([embedding_matrix[:max_words]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Additionally, we freeze the embedding layer (we set its `trainable` attribute to `False`), following the same rationale as what you are \n",
    "already familiar with in the context of pre-trained convnet features: when parts of a model are pre-trained (like our `Embedding` layer), \n",
    "and parts are randomly initialized (like our classifier), the pre-trained parts should not be updated during training to avoid forgetting \n",
    "what they already know. The large gradient update triggered by the randomly initialized layers would be very disruptive to the already \n",
    "learned features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and evaluate\n",
    "\n",
    "Let's compile our model and train it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/5\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 0.6960 - acc: 0.5500 - val_loss: 0.6609 - val_acc: 0.5750\n",
      "Epoch 2/5\n",
      "160/160 [==============================] - 0s 112us/step - loss: 0.2828 - acc: 0.9813 - val_loss: 0.6606 - val_acc: 0.5000\n",
      "Epoch 3/5\n",
      "160/160 [==============================] - 0s 106us/step - loss: 0.1839 - acc: 1.0000 - val_loss: 0.6861 - val_acc: 0.5750\n",
      "Epoch 4/5\n",
      "160/160 [==============================] - 0s 100us/step - loss: 0.1248 - acc: 1.0000 - val_loss: 0.6717 - val_acc: 0.5750\n",
      "Epoch 5/5\n",
      "160/160 [==============================] - 0s 137us/step - loss: 0.0924 - acc: 1.0000 - val_loss: 0.6816 - val_acc: 0.5750\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "history = model.fit(x_train[:200], y_train[:200],\n",
    "                    epochs=5,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.2\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So using pre-train word embeddings improves performance a bit but not too much. Training the rest of the network with so little data it's hard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together: from raw text to word embeddings\n",
    "\n",
    "We will be using a model similar to the one we just went over -- embedding sentences in sequences of vectors, flattening them and training a `Dense` layer on top. But instead of using the pre-tokenized IMDB data packaged in Keras, we will start from scratch, by downloading the original text data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the IMDB data as raw text\n",
    "\n",
    "\n",
    "First, head to `http://ai.stanford.edu/~amaas/data/sentiment/` and download the raw IMDB dataset (if the URL isn't working anymore, just Google \"IMDB dataset\") or take it from `I:\\COURSES\\ITP\\BITY3\\IN726-dsmi-data\\aclImdb.rar`. Uncompress it.\n",
    "\n",
    "Now let's collect the individual training reviews into a list of strings, one string per review, and let's also collect the review labels \n",
    "(positive / negative) into a `labels` list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "imdb_dir = './aclImdb/'\n",
    "train_dir = os.path.join(imdb_dir, 'train')\n",
    "\n",
    "labels = []\n",
    "texts = []\n",
    "\n",
    "for label_type in ['neg', 'pos']:\n",
    "    dir_name = os.path.join(train_dir, label_type)\n",
    "    for fname in os.listdir(dir_name):\n",
    "        if fname[-4:] == '.txt':\n",
    "            f = open(os.path.join(dir_name, fname),encoding=\"utf8\")\n",
    "            texts.append(f.read())\n",
    "            f.close()\n",
    "            if label_type == 'neg':\n",
    "                labels.append(0)\n",
    "            else:\n",
    "                labels.append(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the first movie review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Story of a man who has unnatural feelings for a pig. Starts out with a opening scene that is a terrific example of absurd comedy. A formal orchestra audience is turned into an insane, violent mob by the crazy chantings of it's singers. Unfortunately it stays absurd the WHOLE time with no general narrative eventually making it just too off putting. Even those from the era should be turned off. The cryptic dialogue would make Shakespeare seem easy to a third grader. On a technical level it's better than you might think with some good cinematography by future great Vilmos Zsigmond. Future stars Sally Kirkland and Frederic Forrest can be seen briefly.\""
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And its corresponding labeled sentiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize the data\n",
    "\n",
    "Let's vectorize the texts we collected, and prepare a training and validation split.\n",
    "We will merely be using the concepts we introduced earlier in this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "maxlen = 120  # We will cut reviews after 100 words\n",
    "training_samples = 20000  # We will be training on 200 samples\n",
    "validation_samples = 5000  # We will be validating on 10000 samples\n",
    "max_words = 10000  # We will only consider the top 10,000 words in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 88582 unique tokens.\n",
      "Shape of data tensor: (25000, 120)\n",
      "Shape of label tensor: (25000,)\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "data = pad_sequences(sequences, maxlen=maxlen)\n",
    "\n",
    "labels = np.asarray(labels)\n",
    "print('Shape of data tensor:', data.shape)\n",
    "print('Shape of label tensor:', labels.shape)\n",
    "\n",
    "# Split the data into a training set and a validation set\n",
    "# But first, shuffle the data, since we started from data\n",
    "# where sample are ordered (all negative first, then all positive).\n",
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "labels = labels[indices]\n",
    "\n",
    "x_train = data[:training_samples]\n",
    "y_train = labels[:training_samples]\n",
    "x_test = data[training_samples: training_samples + validation_samples]\n",
    "y_test = labels[training_samples: training_samples + validation_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 474,  809,    9,   13,    3, 9374,   36,  377,    5, 1359,   15,\n",
       "         69,    2,   48,   32, 1046, 1362,    9,   13,    7,    7,   14,\n",
       "        512,   14,   10, 1922,    1, 1807,   20,   10,  694,  614,   48,\n",
       "         10,   13,    8,   15,   40,   31,    1,  422, 7908,  258,   46,\n",
       "        180,   89,  759,   53,   51,   22, 1662,  196,  198,    9,    6,\n",
       "        128, 1290, 2139,   47,   68,   54,  757,   41,    1,    8, 7513,\n",
       "       7422,   39,    1,  757,    4, 6737, 3254,   18,  276,   10,  771,\n",
       "        185,  227,  192,   80,    1,  198,   15,   95,    5, 1258,  135,\n",
       "          7,    7,   10,  383,   11,  120,    5,  256,   34, 1387,    1,\n",
       "       2520, 2129,    2, 4717, 5369,    4,  260,  179,   11,  120,    6,\n",
       "         52,  218,    2,   77,   25,   22, 1783,    5,  103,   50])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_15 (Embedding)     (None, 120, 8)            80000     \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 960)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 32)                30752     \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 110,785\n",
      "Trainable params: 110,785\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten, Dense\n",
    "\n",
    "embedding_dim = 8\n",
    "del model\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_words, embedding_dim, input_length=maxlen))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/4\n",
      "16000/16000 [==============================] - 1s 66us/step - loss: 0.5329 - acc: 0.7256 - val_loss: 0.3621 - val_acc: 0.8427\n",
      "Epoch 2/4\n",
      "16000/16000 [==============================] - 1s 39us/step - loss: 0.2676 - acc: 0.8926 - val_loss: 0.3363 - val_acc: 0.8585\n",
      "Epoch 3/4\n",
      "16000/16000 [==============================] - 1s 40us/step - loss: 0.1828 - acc: 0.9303 - val_loss: 0.3523 - val_acc: 0.8545\n",
      "Epoch 4/4\n",
      "16000/16000 [==============================] - 1s 39us/step - loss: 0.1164 - acc: 0.9601 - val_loss: 0.4074 - val_acc: 0.8472\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=4,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's evaluate the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 0s 12us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3817607293605804, 0.8556]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "And there you have it! you created a machine learning system able to carry out sentiment analysis with decent accuracy, starting from raw text!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
